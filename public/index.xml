<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Home on </title>
    <link>http://localhost:1313/neurips2025/</link>
    <description>Recent content in Home on </description>
    <generator>Hugo</generator>
    <language>en</language>
    <atom:link href="http://localhost:1313/neurips2025/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Call for Papers</title>
      <link>http://localhost:1313/neurips2025/call-for-papers/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/neurips2025/call-for-papers/</guid>
      <description>&lt;h1 id=&#34;call-for-papers&#34;&gt;Call for Papers&lt;/h1&gt;&#xA;&lt;p&gt;We will invite submissions (4-page papers, both technical and positional in nature) covering or bridging the following themes. We note that these themes are not mutually exclusive, and papers may touch on multiple themes.&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;Behavioral accounts&lt;/strong&gt;. What kinds of generalizations have models learned about cognitively important tasks? What kinds of cues, biases, or heuristics might affect a model’s performance on these tasks? What kind of cognitive frameworks best characterize model behaviors?&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;ins&gt;Example topics within scope:&lt;/ins&gt; hypothesis-driven evaluations of high-level cognitive behaviors; understanding how heuristics and task demands affect model behaviors; and fitting cognitive models to deep neural network behavioral data&lt;/li&gt;&#xA;&lt;li&gt;&lt;ins&gt;Example topics potentially out of scope:&lt;/ins&gt; Evaluations of deep learning models which do not make claims about the underlying processes driving their behavior; Behavioral experiments with AI models which seek to further our understanding of the human mind, rather than our understanding of AI models&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;br&gt;&#xA;&lt;ol start=&#34;2&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Processing accounts&lt;/strong&gt;. How are the behaviors learned by models implemented? What algorithms enable the behaviors models perform to execute key high-level cognitive tasks?&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;ins&gt;Example topics within scope:&lt;/ins&gt; Using mechanistic interpretability to understand cognitive processing algorithms; Behavioral investigations of algorithms underlying complex tasks&lt;/li&gt;&#xA;&lt;li&gt;&lt;ins&gt;Example topics potentially out of scope:&lt;/ins&gt; Validation or demonstration of mech interp methods&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;br&gt;&#xA;&lt;ol start=&#34;3&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Learning accounts&lt;/strong&gt;. How do certain cognitive abilities emerge or develop across learning? What properties of the training data distribution or objective functions contribute to downstream behaviors? How does the model’s training environment relate to predispositions supported by the model’s architecture or other forms of inductive bias? Relevant perspectives from cognitive science that could help shed light on these questions include developmental psychology, learning theory, and evolutionary biology.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;ins&gt;Example topics within scope:&lt;/ins&gt; Evaluations of learning inspired by cognitive theories; Understanding models’ inductive biases; Understanding the concepts/rewards learned through alignment; Understanding downstream effects of data distribution on behavior and generalization&lt;/li&gt;&#xA;&lt;li&gt;&lt;ins&gt;Example topics potentially out of scope:&lt;/ins&gt; scaling laws&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;!-- &#xA;We welcome submissions related to any aspects of multimodal representation learning, including but not limited to:&#xA;  * Properties of multimodal representations.&#xA;  * Insights on interactions across modalities.&#xA;  * Novel applications regarding the nature and number of modalities.&#xA;&#xA;&#xA;In particular, we encourage submission that address the following questions:&#xA;  * **Representation:** How do we identify useful properties of multimodal representations?&#xA;    * What semantic information is encoded in the learned representations?&#xA;    * How does the geometry of the representation space affect the quality of the learned representations?&#xA;    * What properties are leveraged for downstream tasks?&#xA;  * **Training:** How can we promote useful properties of multimodal representations?&#xA;    * What are the limits of representation models, in regard to the number of modalities?&#xA;    * How do different learning objectives influence the resulting representations?&#xA;    * How do we promote the robustness of the representations to adversarial attacks, missing input modalities, and noise?&#xA;  * **Modalities:** What makes a modality different? How can we improve their interactions?&#xA;    * How can we quantify the (dis)similarity between modalities?&#xA;    * How do different modalities contribute to the semantics of the learned representations?&#xA;    * What are the representation benefits of having multimodal observations as opposed to just a single modality?&#xA;&#xA;The MRL workshop has the objective to bring together experts from the multimodal learning community in order to advance these fundamental questions and discuss the future of the field. We invite submissions that present analysis of the properties of multimodal representations, insights on interactions across modalities, as well as novel applications regarding the nature and number of modalities employed. --&gt;&#xA;&lt;h2 id=&#34;submission&#34;&gt;Submission&lt;/h2&gt;&#xA;&lt;p&gt;The submission will be open on OpenReview](&lt;a href=&#34;https://openreview.net/group?id=neurips.cc/2025/Workshop/CogInterp&#34;&gt;https://openreview.net/group?id=neurips.cc/2025/Workshop/CogInterp&lt;/a&gt;) between July 5 and August 22, 2025 (midnight AoE). For all relevant dates, please see &lt;a href=&#34;http://localhost:1313/neurips2025/#dates&#34;&gt;Important Dates&lt;/a&gt;. The formatting instructions are provided below.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Formatting Instructions</title>
      <link>http://localhost:1313/neurips2025/formatting-instructions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/neurips2025/formatting-instructions/</guid>
      <description>&lt;h1 id=&#34;formatting-instructions&#34;&gt;Formatting Instructions&lt;/h1&gt;&#xA;&lt;h2 id=&#34;style--author-instructions&#34;&gt;Style &amp;amp; Author Instructions&lt;/h2&gt;&#xA;&lt;p&gt;Submissions should be formatted using the &lt;a href=&#34;https://github.com/ICLR/Master-Template/raw/master/iclr2023.zip&#34;&gt;ICLR 2023 latex template and formatting instructions&lt;/a&gt;. Papers must be submitted as a PDF file and there will be a strict upper limit of 4 pages for the main text, which should include all main results, figures, and tables. This page limit applies to both the initial and final camera ready version., including all main results, figures, and tables. There is no page limit for the citations, and additional appendices for supplementary details are allowed, but reviewers are not expected to take the appendices into account.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Invited Speakers</title>
      <link>http://localhost:1313/neurips2025/speakers/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/neurips2025/speakers/</guid>
      <description>&lt;h1 id=&#34;invited-speakers&#34;&gt;Invited Speakers&lt;/h1&gt;&#xA;&lt;div class=&#34;list-of-people&#34;&gt;&#xA;    &lt;div class=&#34;person&#34;&gt;&#xA;        &lt;td&gt;&lt;img src=&#34;http://localhost:1313/neurips2025/speakers/siddharth.png&#34;&gt;&lt;/td&gt;&#xA;        &lt;td&gt;&lt;a href=&#34;https://homepages.inf.ed.ac.uk/snaraya3/&#34; target=&#34;_blank&#34;&gt;Siddharth N.&lt;/a&gt;&lt;/td&gt;&#xA;    &lt;/div&gt;&#xA;    &lt;div class=&#34;person&#34;&gt;&#xA;        &lt;td&gt;&lt;img src=&#34;http://localhost:1313/neurips2025/speakers/zeynep.jpg&#34;&gt;&lt;/td&gt;&#xA;        &lt;td&gt;&lt;a href=&#34;https://www.eml-unitue.de/people/zeynep-akata&#34; target=&#34;_blank&#34;&gt;Zeynep Akata&lt;/a&gt;&lt;/td&gt;&#xA;    &lt;/div&gt;&#xA;    &lt;div class=&#34;person&#34;&gt;&#xA;        &lt;td&gt;&lt;img src=&#34;http://localhost:1313/neurips2025/speakers/arsha.jpeg&#34;&gt;&lt;/td&gt;&#xA;        &lt;td&gt;&lt;a href=&#34;https://a-nagrani.github.io/&#34; target=&#34;_blank&#34;&gt;Arsha Nagrani&lt;/a&gt;&lt;/td&gt;&#xA;    &lt;/div&gt;&#xA;    &lt;div class=&#34;person&#34;&gt;&#xA;        &lt;td&gt;&lt;img src=&#34;http://localhost:1313/neurips2025/speakers/paul.jpg&#34;&gt;&lt;/td&gt;&#xA;        &lt;td&gt;&lt;a href=&#34;https://www.cs.cmu.edu/~pliang/&#34; target=&#34;_blank&#34;&gt;Paul Pu Liang&lt;/a&gt;&lt;/td&gt;&#xA;    &lt;/div&gt;&#xA;    &lt;div class=&#34;person&#34;&gt;&#xA;        &lt;td&gt;&lt;img src=&#34;http://localhost:1313/neurips2025/speakers/kristen.jpg&#34;&gt;&lt;/td&gt;&#xA;        &lt;td&gt;&lt;a href=&#34;https://www.cs.utexas.edu/users/grauman/&#34; target=&#34;_blank&#34;&gt;Kristen Grauman&lt;/a&gt;&lt;/td&gt;&#xA;    &lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&lt;script&gt;&#xA;  var ul = document.querySelector(&#39;div.list-of-people&#39;);&#xA;  for (var i = ul.children.length; i &gt;= 0; i--) {&#xA;      ul.appendChild(ul.children[Math.random() * i | 0]);&#xA;  }&#xA;&lt;/script&gt;&#xA;&lt;div id=&#34;bio-zeynep&#34;&gt;&#xA;&lt;h2 id=&#34;zeynep-akata&#34;&gt;Zeynep Akata&lt;/h2&gt;&#xA;&lt;p&gt;Zeynep Akata is a professor of Computer Science (W3) within the Cluster of&#xA;Excellence Machine Learning at the University of Tübingen.  After completing&#xA;her PhD at the INRIA Rhone Alpes with Prof Cordelia Schmid (2014), she&#xA;worked as a post-doctoral researcher at the Max Planck Institute for&#xA;Informatics with Prof Bernt Schiele (2014-17) and at University of&#xA;California Berkeley with Prof Trevor Darrell (2016-17). Before moving to&#xA;Tübingen in October 2019, she was an assistant professor at the University&#xA;of Amsterdam with Prof Max Welling (2017-19). She received a Lise-Meitner&#xA;Award for Excellent Women in Computer Science from Max Planck Society in&#xA;2014, a young scientist honour from the Werner-von-Siemens-Ring foundation&#xA;in 2019 and an ERC-2019 Starting Grant from the European Commission. Her&#xA;research interests include multimodal learning and explainable AI.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Organizers</title>
      <link>http://localhost:1313/neurips2025/organizers-reviewers/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/neurips2025/organizers-reviewers/</guid>
      <description>&lt;h1 id=&#34;organizers&#34;&gt;Organizers&lt;/h1&gt;&#xA;&lt;div class=&#34;list-of-people&#34;&gt;&#xA;    &lt;div class=&#34;person&#34;&gt;&#xA;        &lt;img src=&#34;http://localhost:1313/neurips2025/organizing-team/jenn.png&#34;&gt;&#xA;        &lt;a href=&#34;https://jennhu.github.io&#34; target=&#34;_blank&#34;&gt;Jennifer Hu&lt;/a&gt;&#xA;    &lt;/div&gt;&#xA;    &lt;div class=&#34;person&#34;&gt;&#xA;        &lt;img src=&#34;http://localhost:1313/neurips2025/organizing-team/ekdeep.jpeg&#34;&gt;&#xA;        &lt;a href=&#34;https://ekdeepslubana.github.io&#34; target=&#34;_blank&#34;&gt;Ekdeep Singh Lubana&lt;/a&gt;&#xA;    &lt;/div&gt;&#xA;    &lt;div class=&#34;person&#34;&gt;&#xA;        &lt;img src=&#34;http://localhost:1313/neurips2025/organizing-team/eric.jpg&#34;&gt;&#xA;        &lt;a href=&#34;https://scholar.google.com/citations?user=wpppofoAAAAJ&#34; target=&#34;_blank&#34;&gt;Eric Bigelow&lt;/a&gt;&#xA;    &lt;/div&gt;&#xA;    &lt;!--  --&gt;&#xA;    &lt;!-- TODO: images for each of these --&gt;&#xA;    &lt;!--  --&gt;&#xA;    &lt;div class=&#34;person&#34;&gt;&#xA;        &lt;img src=&#34;http://localhost:1313/neurips2025/organizing-team/kanishk.jpeg&#34;&gt;&#xA;        &lt;a href=&#34;https://www.kanishkgandhi.com&#34; target=&#34;_blank&#34;&gt;Kanishk Gandhi&lt;/a&gt;&#xA;    &lt;/div&gt;&#xA;    &lt;div class=&#34;person&#34;&gt;&#xA;        &lt;img src=&#34;http://localhost:1313/neurips2025/organizing-team/laura.jpg&#34;&gt;&#xA;        &lt;a href=&#34;https://lauraruis.github.io&#34; target=&#34;_blank&#34;&gt;Laura Ruis&lt;/a&gt;&#xA;    &lt;/div&gt;&#xA;    &lt;div class=&#34;person&#34;&gt;&#xA;        &lt;img src=&#34;http://localhost:1313/neurips2025/organizing-team/thomas.png&#34;&gt;&#xA;        &lt;a href=&#34;https://thomasfel.me&#34; target=&#34;_blank&#34;&gt;Thomas Fel&lt;/a&gt;&#xA;    &lt;/div&gt;&#xA;    &lt;div class=&#34;person&#34;&gt;&#xA;        &lt;img src=&#34;http://localhost:1313/neurips2025/organizing-team/ellie.jpg&#34;&gt;&#xA;        &lt;a href=&#34;https://cs.brown.edu/people/epavlick/&#34; target=&#34;_blank&#34;&gt;Ellie Pavlick&lt;/a&gt;&#xA;    &lt;/div&gt;&#xA;    &lt;div class=&#34;person&#34;&gt;&#xA;        &lt;img src=&#34;http://localhost:1313/neurips2025/organizing-team/noah.jpeg&#34;&gt;&#xA;        &lt;a href=&#34;https://cocolab.stanford.edu/ndg&#34; target=&#34;_blank&#34;&gt;Noah Goodman&lt;/a&gt;&#xA;    &lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&lt;!-- &lt;script&gt;&#xA;  var ul = document.querySelector(&#39;div.list-of-people&#39;);&#xA;  for (var i = ul.children.length; i &gt;= 0; i--) {&#xA;      ul.appendChild(ul.children[Math.random() * i | 0]);&#xA;  }&#xA;&lt;/script&gt; --&gt;&#xA;&lt;h2 id=&#34;contact&#34;&gt;Contact&lt;/h2&gt;&#xA;&lt;p&gt;For any questions or comments, please contact us at &lt;a href=&#34;mailto:coginterp@gmail.com&#34;&gt;coginterp@gmail.com&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;hr /&gt;&#xA;&lt;h1 id=&#34;acknowledgements&#34;&gt;Acknowledgements&lt;/h1&gt;&#xA;&lt;p&gt;We acknowledge and greatly appreciate the help of all reviewers and&#xA;members of the program committee who made this workshop possible.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Reviewers</title>
      <link>http://localhost:1313/neurips2025/reviewers/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/neurips2025/reviewers/</guid>
      <description>&lt;h1 id=&#34;reviewers&#34;&gt;Reviewers&lt;/h1&gt;&#xA;&lt;p&gt;Adam Li, Columbia University&lt;/p&gt;&#xA;&lt;p&gt;Alexander Hägele, ETHZ - ETH Zurich&lt;/p&gt;&#xA;&lt;p&gt;Biwei Huang, Carnegie Mellon University&lt;/p&gt;&#xA;&lt;p&gt;Bohdan Kivva, University of Chicago&lt;/p&gt;&#xA;&lt;p&gt;Bryon Aragam, University of Chicago&lt;/p&gt;&#xA;&lt;p&gt;Chandler Squires, Massachusetts Institute of Technology&lt;/p&gt;&#xA;&lt;p&gt;Cian Eastwood, University of Edinburgh&lt;/p&gt;&#xA;&lt;p&gt;Daniel Malinsky, Johns Hopkins University&lt;/p&gt;&#xA;&lt;p&gt;Davide Talon, Università degli Studi di Genova, Istituto Italiano di Tecnologia&lt;/p&gt;&#xA;&lt;p&gt;Dhanya Sridhar, Université de Montréal and Mila-Quebec AI Institute&lt;/p&gt;&#xA;&lt;p&gt;Furui Liu, Huawei Technologies Ltd.&lt;/p&gt;&#xA;&lt;p&gt;Gargi Balasubramaniam, University of Illinois, Urbana Champaign&lt;/p&gt;</description>
    </item>
    <item>
      <title>Schedule and Format</title>
      <link>http://localhost:1313/neurips2025/schedule/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/neurips2025/schedule/</guid>
      <description>&lt;h1 id=&#34;workshop-schedule&#34;&gt;Workshop Schedule&lt;/h1&gt;&#xA;&lt;div style=&#34;width: 100%; font-size: smaller; text-align: center; margin-bottom: 18px; margin-top: 18px;&#34;&gt;&#xA;    Legend:&#xA;    &lt;span class=&#34;invited&#34;&gt;invited&lt;/span&gt; · &#xA;    &lt;span class=&#34;contributed&#34;&gt;contributed&lt;/span&gt; ·&#xA;    &lt;span class=&#34;poster&#34;&gt;poster&lt;/span&gt; · &#xA;    &lt;span class=&#34;break&#34;&gt;break&lt;/span&gt;&#xA;&lt;/div&gt;&#xA;&lt;table class=&#34;schedule&#34;&gt;&#xA;    &lt;tr&gt;&#xA;        &lt;th style=&#34;width:40%&#34;&gt;Time&lt;/th&gt;&#xA;        &lt;th&gt;Program&lt;/th&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr&gt;&#xA;        &lt;td&gt;08:55 - 09:00&lt;/td&gt;&#xA;        &lt;td&gt;Introduction and Opening Remarks&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr class=&#34;invited&#34;&gt;&#xA;        &lt;td&gt;09:00 - 09:30&lt;/td&gt;&#xA;        &lt;td&gt;Invited Talk 1&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr class=&#34;invited&#34;&gt;&#xA;        &lt;td&gt;09:30 - 10:00&lt;/td&gt;&#xA;        &lt;td&gt;Invited Talk 2&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr class=&#34;contributed&#34;&gt;&#xA;        &lt;td&gt;10:00 - 10:15&lt;/td&gt;&#xA;        &lt;td&gt;Spotlight Talk 1&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr class=&#34;break&#34;&gt;&#xA;        &lt;td&gt;10:15 - 10:30&lt;/td&gt;&#xA;        &lt;td&gt;Coffee Break&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;!--  --&gt;&#xA;    &lt;!--  --&gt;&#xA;    &lt;tr class=&#34;invited&#34;&gt;&#xA;        &lt;td&gt;10:30 - 11:00&lt;/td&gt;&#xA;        &lt;td&gt;Invited Talk 3&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr class=&#34;invited&#34;&gt;&#xA;        &lt;td&gt;11:00 - 11:30&lt;/td&gt;&#xA;        &lt;td&gt;Invited Talk 4&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr class=&#34;contributed&#34;&gt;&#xA;        &lt;td&gt;11:30 - 11:45&lt;/td&gt;&#xA;        &lt;td&gt;Spotlight Talk 2&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;!--  --&gt;&#xA;    &lt;!--  --&gt;&#xA;    &lt;tr class=&#34;break&#34;&gt;&#xA;        &lt;td&gt;11:45 - 13:15&lt;/td&gt;&#xA;        &lt;td&gt;Lunch&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr class=&#34;poster&#34;&gt;&#xA;        &lt;td&gt;13:15 - 14:45&lt;/td&gt;&#xA;        &lt;td&gt;Poster Session&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;!--  --&gt;&#xA;    &lt;!--  --&gt;&#xA;    &lt;tr class=&#34;invited&#34;&gt;&#xA;        &lt;td&gt;14:45 - 15:15&lt;/td&gt;&#xA;        &lt;td&gt;Invited Talk 5&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr class=&#34;invited&#34;&gt;&#xA;        &lt;td&gt;15:15 - 15:45&lt;/td&gt;&#xA;        &lt;td&gt;Invited Talk 6&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr class=&#34;break&#34;&gt;&#xA;        &lt;td&gt;15:45 - 16:00&lt;/td&gt;&#xA;        &lt;td&gt;Coffee Break&lt;/td&gt;&#xA;        &lt;!-- &lt;td&gt;-&lt;/td&gt; --&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;!--  --&gt;&#xA;    &lt;!--  --&gt;&#xA;    &lt;tr class=&#34;contributed&#34;&gt;&#xA;        &lt;td&gt;16:00 - 17:00&lt;/td&gt;&#xA;        &lt;td&gt;Panel Discussion (with all invited speakers)&lt;/td&gt;&#xA;        &lt;!-- &lt;td&gt;Live&lt;/td&gt; --&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr&gt;&#xA;        &lt;td&gt;17:00 - 17:10&lt;/td&gt;&#xA;        &lt;td&gt;Closing Remarks &amp;amp; Best Paper Award&lt;/td&gt;&#xA;        &lt;!-- &lt;td&gt;Live&lt;/td&gt; --&gt;&#xA;    &lt;/tr&gt;&#xA;&lt;/table&gt;&#xA;&lt;div style=&#34;width: 100%; font-size: smaller; text-align: center; margin-top: 18px;&#34;&gt;&#xA;    &lt;em&gt;All times are for current local time in San Diego, USA.&lt;/em&gt;&#xA;&lt;/div&gt;&#xA;&lt;h2 id=&#34;format&#34;&gt;Format&lt;/h2&gt;&#xA;&lt;p&gt;The workshop is part of NeurIPS and all attendees are requied to register for NeurIPS.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
